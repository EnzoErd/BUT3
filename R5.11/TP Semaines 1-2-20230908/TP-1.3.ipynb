{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des variables categorielles : one-hot encoding\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traiter les variables categorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from helpers import tp1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "iowa_file_path = 'data/iowa_data.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "home_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "# Selectionner la cible\n",
    "y = home_data.SalePrice\n",
    "\n",
    "# Pour simplifier, nous allons supprimer les colonnes avec des valeurs manquantes\n",
    "cols_with_missing = ...\n",
    "X = ...\n",
    "...\n",
    "\n",
    "# Diviser les données en sous-ensembles d'entrainement et de validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "\n",
    "tp1_2.step5.check(X_train, X_valid, y_train, y_valid)\n",
    "# tp1_2.step5.hint()\n",
    "# tp1_2.step5.solution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fonction pour entrainer le modèle et evaluer la performance\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "# Le code suivant donne une erreur car il y a des variables catégorielles \n",
    "score = score_dataset(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supprimer les colonnes avec des données catégorielles\n",
    "\n",
    "Vous commencerez par l'approche la plus simple. Utilisez la cellule de code ci-dessous pour prétraiter les données dans X_train et X_valid pour supprimer les colonnes avec des données catégorielles. Définissez les DataFrames prétraités sur drop_X_train et drop_X_valid, respectivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplissez les lignes ci-dessous : supprimez les colonnes dans les données d'entraînement et de validation\n",
    "drop_X_train = X_train...\n",
    "drop_X_valid = ...\n",
    "# # Le code suivant donne une erreur car il y a des variables catégorielles\n",
    "# score = score_dataset(X_train, X_valid, y_train, y_valid)\n",
    "# Le code suivant fonctionne après avoir supprimé les variables catégorielles\n",
    "score = ...\n",
    "print (score)\n",
    "\n",
    "tp1_2.step6.check(drop_X_train, drop_X_valid, score)\n",
    "# tp1_2.step6.hint()\n",
    "# tp1_2.step6.solution()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage one-hot et encodage ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colonnes de catégorie dans les données d'entraînement\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Obtenir le nombre d'entrées uniques dans chaque colonne avec des données catégorielles\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Afficher le nombre d'entrées uniques par colonne, par ordre croissant\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étude de la cardinalité\n",
    "\n",
    "La sortie ci-dessus montre, pour chaque colonne avec des données catégorielles, le nombre de valeurs uniques dans la colonne. Par exemple, la colonne \"Street\" dans les données d'entraînement a deux valeurs uniques : \"Grvl\" et \"Pave\", correspondant respectivement à une route de gravier et à une route goudronnée.\n",
    "\n",
    "Nous appelons le nombre d'entrées uniques d'une variable catégorielle la cardinalité de cette variable catégorielle. Par exemple, la variable 'Street' a la cardinalité 2.\n",
    "\n",
    "Utilisez la sortie ci-dessus pour répondre aux questions ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplissez la ligne ci-dessous : Combien de variables catégorielles \n",
    "# dans les données d'apprentissage ont une cardinalité supérieure à 10 ?\n",
    "high_cardinality_numcols = ...\n",
    "\n",
    "# Remplissez la ligne ci-dessous : Combien de colonnes sont nécessaires\n",
    "# pour encoder One-Hot la variable 'Neighborhood' dans les données d'apprentissage ?\n",
    "num_cols_neighborhood = ...\n",
    "\n",
    "tp1_2.step7.check(high_cardinality_numcols, num_cols_neighborhood)\n",
    "# tp1_2.step7.hint()\n",
    "# tp1_2.step7.solution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les ensembles de données volumineux comportant de nombreuses lignes, l'encodage One-Hot peut considérablement augmenter la taille de l'ensemble de données. Pour cette raison, nous n'encoderons généralement que des colonnes avec une cardinalité relativement faible. Ensuite, les colonnes à cardinalité élevée peuvent soit être supprimées de l'ensemble de données, soit utiliser un encodage ordinal.\n",
    "\n",
    "Par exemple, considérons un ensemble de données avec 10 000 lignes et contenant une colonne catégorielle avec 100 entrées uniques.\n",
    "\n",
    "Si cette colonne est remplacée par l'encodage one-hot correspondant, combien d'entrées sont ajoutées à l'ensemble de données ?\n",
    "Si nous remplaçons plutôt la colonne par l'encodage ordinal, combien d'entrées sont ajoutées ?\n",
    "Utilisez vos réponses pour remplir les lignes ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplissez la ligne ci-dessous : Combien d'entrées sont ajoutées à \n",
    "# l'ensemble de données en remplaçant la colonne par un encodage unique ?\n",
    "OH_entries_added = ...\n",
    "\n",
    "# Remplissez la ligne ci-dessous : Combien d'entrées sont ajoutées \n",
    "# au jeu de données en remplaçant la colonne par un encodage ordinal ?\n",
    "label_entries_added = ...\n",
    "\n",
    "tp1_2.step8.check(OH_entries_added, label_entries_added)\n",
    "# tp1_2.step8.hint()\n",
    "# tp1_2.step8.solution()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, vous expérimenterez l'encodage One-Hot. Mais, au lieu d'encoder toutes les variables catégorielles dans l'ensemble de données, vous le ferez que pour les colonnes avec une cardinalité inférieure à 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes qui seront encodées en one-hot\n",
    "low_cardinality_cols = ...\n",
    "\n",
    "# Colonnes qui seront supprimées du dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)\n",
    "\n",
    "tp1_2.step9.check(low_cardinality_cols, high_cardinality_cols)\n",
    "# tp1_2.step9.hint()\n",
    "# tp1_2.step9.solution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la cellule de code suivante pour encoder One-Hot les données dans `X_train` et `X_valid`. Définissez les DataFrames prétraités sur `OH_X_train` et `OH_X_valid`, respectivement.\n",
    "- La liste complète des colonnes catégorielles du jeu de données se trouve dans la liste Python `object_cols`.\n",
    "- Vous ne devez encoder qu'une seule fois les colonnes catégorielles dans `low_cardinality_cols`. Toutes les autres colonnes catégorielles doivent être supprimées de l'ensemble de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Appliquer un encodeur one-hot à chaque colonne avec des données catégorielles\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(...))\n",
    "\n",
    "# One-hot encodage supprime l'index; le remettre\n",
    "OH_cols.index = X.index\n",
    "\n",
    "# Supprimer les colonnes catégorielles (sera remplacé par l'encodage one-hot)\n",
    "num_X = X.drop(..., axis=1)\n",
    "\n",
    "# Combiner les colonnes encodées one-hot et caractéristiques numériques\n",
    "OH_X = ...\n",
    "\n",
    "# Assurer que toutes les colonnes sont des strings\n",
    "OH_X.columns = OH_X.columns.astype(str)\n",
    "\n",
    "OH_X_train, OH_X_valid, y_train, y_valid = train_test_split(OH_X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "score = score_dataset(OH_X_train, OH_X_valid, y_train, y_valid)\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\", score) \n",
    "\n",
    "tp1_2.step10.check(OH_X_train, OH_X_valid, y_train, y_valid, score)\n",
    "# tp1_2.step10.hint()\n",
    "# tp1_2.step10.solution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
